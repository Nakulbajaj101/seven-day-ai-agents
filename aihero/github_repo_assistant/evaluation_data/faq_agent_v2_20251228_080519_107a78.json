{"agent_name": "faq_agent_v2", "system_prompt": ["You are a helpful assistant for a course.  \n\nUse the search tool to find relevant information from the document materials before answering questions.  \n\nIf you can find specific information through search, use it to provide accurate answers.\n\nAlways include references by citing the filename of the source material you used.  \nWhen citing the reference, replace \"faq-main\" by the full path to the GitHub repository: \"https://github.com/evidentlyai/docs/tree/main\"\nFormat: [LINK TITLE](FULL_GITHUB_LINK)\n\nIf the search doesn't return relevant results, let the user know and provide general guidance."], "provider": "openai", "model": "gpt-4o-mini", "tools": ["hybrid_search"], "messages": [{"parts": [{"content": "How can you effectively use Evidently AI to evaluate and monitor LLMs in real-time?", "timestamp": "2025-12-28T08:05:07.353293Z", "part_kind": "user-prompt"}], "timestamp": "2025-12-28T08:05:07.353493Z", "instructions": "You are a helpful assistant for a course.  \n\nUse the search tool to find relevant information from the document materials before answering questions.  \n\nIf you can find specific information through search, use it to provide accurate answers.\n\nAlways include references by citing the filename of the source material you used.  \nWhen citing the reference, replace \"faq-main\" by the full path to the GitHub repository: \"https://github.com/evidentlyai/docs/tree/main\"\nFormat: [LINK TITLE](FULL_GITHUB_LINK)\n\nIf the search doesn't return relevant results, let the user know and provide general guidance.", "kind": "request", "run_id": "70f926e8-8bfe-40b6-a233-25d0cb4398b2", "metadata": null}, {"parts": [{"tool_name": "hybrid_search", "args": "{\"query\":\"evaluate monitor LLMs real-time site:github.com/evidentlyai/docs\"}", "tool_call_id": "call_lDUWzVqWrVRyIU4WhKJAVU0E", "id": null, "provider_details": null, "part_kind": "tool-call"}], "usage": {"input_tokens": 175, "cache_write_tokens": 0, "cache_read_tokens": 0, "output_tokens": 30, "input_audio_tokens": 0, "cache_audio_read_tokens": 0, "output_audio_tokens": 0, "details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}}, "model_name": "gpt-4o-mini-2024-07-18", "timestamp": "2025-12-28T08:05:08.273199Z", "kind": "response", "provider_name": "openai", "provider_url": "https://api.openai.com/v1/", "provider_details": {"finish_reason": "tool_calls", "timestamp": "2025-12-28T08:05:07Z"}, "provider_response_id": "chatcmpl-Crg3vUAAoYQGaBubGRFPipHOio02X", "finish_reason": "tool_call", "run_id": "70f926e8-8bfe-40b6-a233-25d0cb4398b2", "metadata": null}, {"parts": [{"tool_name": "hybrid_search", "content": [{"title": "LLM-as-a-jury", "description": "Evaluate the LLM outputs with multiple LLMs.", "filename": "docs-main/examples/llm_jury.mdx", "section": "## Introduction to LLM Jury Evaluation\n\nThis evaluation approach uses multiple LLMs to evaluate the same output. You can do this to obtain an aggregate evaluation result\u2014e.g., consider an output a \"pass\" only if all or the majority of LLMs approve\u2014or to explicitly surface disagreements.\n\nFor more details, visit the [blog explaining the concept of LLM jury](https://www.evidentlyai.com/blog/llm-judges-jury)."}, {"title": "Evidently and GitHub actions", "description": "Testing LLM outputs as part of the CI/CD flow.", "filename": "docs-main/examples/github_actions.mdx", "section": "## Code Example and Tutorial\n\n\ud83d\udc49 Check the full tutorial and example repository: [Evidently CI Example](https://github.com/evidentlyai/evidently-ci-example).\n\nThe action is also available on GitHub Marketplace: [Run Evidently Report](https://github.com/marketplace/actions/run-evidently-report)."}, {"title": "LLM-as-a-jury", "description": "Evaluate the LLM outputs with multiple LLMs.", "filename": "docs-main/examples/llm_jury.mdx", "section": "## Step 1: Set Up Evaluator LLMs\n\n### Pass API Keys\n\nYou need to pass the API keys for the LLMs you'll use as judges.\n\n```python\nimport os\nos.environ[\"OPENAI_API_KEY\"] = \"YOUR KEY\"\nos.environ[\"GEMINI_API_KEY\"] = \"YOUR KEY\"\nos.environ[\"ANTHROPIC_API_KEY\"] = \"YOUR KEY\"\n```\n\n<Info>\nYou can use any other LLMs, including self-hosted ones. Check the [docs on LLM judges](/metrics/customize_llm_judge).\n</Info>\n\n### Optional: Set Up Evidently Cloud Workspace\n\n```python\nws = CloudWorkspace(token=\"YOUR_API_TOKEN\", url=\"https://app.evidently.cloud\")\n```\n\nCreate a project to store your evaluation results:\n\n```python\nproject = ws.create_project(\"LLM jury\", org_id=\"YOUR ORG ID\")\nproject.description = \"Evals with different LLMs\"\n```"}, {"title": "LLM-as-a-jury", "description": "Evaluate the LLM outputs with multiple LLMs.", "filename": "docs-main/examples/llm_jury.mdx", "section": "## Conclusion\n\nBy following these steps, you'll successfully evaluate email appropriateness using multiple LLMs and can explore individual evaluations and discrepancies among the models."}, {"title": "LLM-as-a-jury", "description": "Evaluate the LLM outputs with multiple LLMs.", "filename": "docs-main/examples/llm_jury.mdx", "section": "## Step 4: Create a Panel of LLM Judges\n\n### Evaluate Emails with Different Judges\n\nWe will create evaluators from multiple LLM providers using the same evaluation prompt. The following code scores the \"generated email\" column using three different judges.\n\n```python\nllm_evals = Dataset.from_pandas(\n    eval_df,\n    data_definition=DataDefinition(),\n    descriptors=[\n        LLMEval(\"generated email\", template=us_corp_email_appropriateness,\n                provider=\"openai\", model=\"gpt-4o-mini\", alias=\"OpenAI_judge_US\",\n                tests=[eq(\"APPROPRIATE\", column=\"OpenAI_judge_US\", alias=\"GPT approves\")]),\n        ...\n    ],\n    TestSummary(success_all=True, success_count=True, success_rate=True, alias=\"Approve\"),\n)\n```\n\n### Flagging Disagreements\n\nTo explicitly flag disagreements among LLMs, let\u2019s add a custom descriptor:\n\n```python\ndef judges_disagree(data: DatasetColumn) -> DatasetColumn:\n    return DatasetColumn(\n        type=\"cat\",\n        data=pd.Series([\n            \"DISAGREE\" if val not in [0.0, 1.0] else \"AGREE\"\n            for val in data.data]))\n\nllm_evals.add_descriptors(descriptors=[\n    CustomColumnDescriptor(\"Approve_success_rate\", judges_disagree, alias=\"Do LLMs disagree?\"),\n])\n```"}, {"title": "LLM Evaluation", "description": "Evaluate text outputs in under 5 minutes", "filename": "docs-main/quickstart_llm.mdx", "section": "## Introduction to Evidently\n\nEvidently helps you evaluate LLM outputs automatically. The platform enables comparisons of prompts and models, along with regression or adversarial tests, providing clear and repeatable checks. This leads to faster iterations, more confident decisions, and fewer surprises in production."}, {"title": "Text Evals", "description": "Overview of the Text Evals Preset.", "filename": "docs-main/metrics/preset_text_evals.mdx", "section": "## Use Cases\n\nYou can use this Preset in various scenarios:\n\n* **LLM experiments.** Visually explore evaluation results while experimenting on prompts, model versions, etc., and compare different runs.\n\n* **LLM observability.** Run evaluations on production data and track resulting statistics over time."}, {"title": "Self-hosting", "description": "How to self-host the open-source Evidently UI service.", "icon": "window-restore", "filename": "docs-main/docs/setup/self-hosting.mdx", "section": "## Tutorials\n\n1. Check this tutorial for a simple end-to-end example:\n\n   [Evidently UI tutorial](https://github.com/evidentlyai/evidently/blob/main/examples/service/workspace_tutorial.ipynb): How to create a workspace, project, and run Reports.\n\n2. Check this extended tutorial that shows LLM judge evaluation over collected traces and prompt optimization using a local workspace. There is also a [video walkthrough](https://youtu.be/Gem8TG6wNhU).\n\n   [LLM evaluation for tweet generation using local workspace](https://github.com/evidentlyai/community-examples/blob/main/tutorials/local_content_generation.ipynb)."}, {"title": "Tracing", "description": "How to capture LLM inputs and outputs and evaluate them.", "filename": "docs-main/quickstart_tracing.mdx", "section": "## What's Next?\n\nCheck the quickstart on [LLM evaluations](/quickstart_llm) for more details: how to run other evaluation methods, including LLM as a judge, or test for specific conditions.\n\nNeed help? Ask in our [Discord community](https://discord.com/invite/xZjKRaNp8b)."}, {"title": "Tracing", "description": "How to capture LLM inputs and outputs and evaluate them.", "filename": "docs-main/quickstart_tracing.mdx", "section": "## Overview\n\nThis tutorial shows how to set up tracing for an LLM app, collect its inputs and outputs, view them in Evidently Cloud, and optionally run evaluations. You will use the following tools:\n\n* **Tracely**: An open-source tracing library based on OpenTelemetry.\n* **Evidently**: An open-source library to run LLM evaluations and interact with Evidently Cloud.\n* **Evidently Cloud**: A web platform to view traces and run evaluations.\n* **OpenAI**: Used to simulate an LLM application.\n\n<Info>\n  Need help? Ask on [Discord](https://discord.com/invite/xZjKRaNp8b).\n</Info>"}], "tool_call_id": "call_lDUWzVqWrVRyIU4WhKJAVU0E", "metadata": null, "timestamp": "2025-12-28T08:05:08.318165Z", "part_kind": "tool-return"}], "timestamp": "2025-12-28T08:05:08.318404Z", "instructions": "You are a helpful assistant for a course.  \n\nUse the search tool to find relevant information from the document materials before answering questions.  \n\nIf you can find specific information through search, use it to provide accurate answers.\n\nAlways include references by citing the filename of the source material you used.  \nWhen citing the reference, replace \"faq-main\" by the full path to the GitHub repository: \"https://github.com/evidentlyai/docs/tree/main\"\nFormat: [LINK TITLE](FULL_GITHUB_LINK)\n\nIf the search doesn't return relevant results, let the user know and provide general guidance.", "kind": "request", "run_id": "70f926e8-8bfe-40b6-a233-25d0cb4398b2", "metadata": null}, {"parts": [{"content": "To effectively use Evidently AI for evaluating and monitoring large language models (LLMs) in real-time, you can utilize several key features and approaches:\n\n1. **LLM Jury Evaluation**:\n   - This method involves using multiple LLMs to evaluate the same output. You can aggregate results and only consider an output a \"pass\" if it is approved by all or a majority of the evaluating LLMs. This also allows you to identify discrepancies among different models. You will need to set up evaluator models and pass API keys for the LLMs being used.\n   - Example setup:\n     ```python\n     import os\n     os.environ[\"OPENAI_API_KEY\"] = \"YOUR KEY\"\n     os.environ[\"GEMINI_API_KEY\"] = \"YOUR KEY\"\n     os.environ[\"ANTHROPIC_API_KEY\"] = \"YOUR KEY\"\n     ```\n   - Create a project in Evidently Cloud to store evaluation results.\n   - Additional details can be found in the tutorial: [LLM-as-a-jury](https://github.com/evidentlyai/docs/tree/main/docs-main/examples/llm_jury.mdx).\n\n2. **Integration with CI/CD**:\n   - Use Evidently AI as part of your Continuous Integration/Continuous Deployment (CI/CD) workflow. This allows you to automatically evaluate LLM outputs every time you make changes, ensuring rapid feedback loops and high confidence in production. Check the tutorial in the GitHub actions example: [Evidently CI Example](https://github.com/evidentlyai/docs/tree/main/docs-main/examples/github_actions.mdx).\n\n3. **Observability and Experimentation**:\n   - Evidently AI provides tools for LLM observability by allowing you to run evaluations on production data and track metrics over time. You can explore evaluation results visually, compare various models and prompts, and conduct regression or adversarial tests. This enhances your ability to quickly iterate and stabilize your LLM deployments.\n\n4. **Tracing Capabilities**:\n   - Set up tracing for your LLM applications to capture inputs and outputs, which can then be evaluated in real-time. This involves using open-source libraries like Tracely and Evidently to collect and analyze the data seamlessly. More details are available in the tracing quickstart guide: [Tracing LLM Inputs and Outputs](https://github.com/evidentlyai/docs/tree/main/docs-main/quickstart_tracing.mdx).\n\nBy utilizing these approaches, you can ensure that your LLMs are evaluated comprehensively and monitored effectively in real-time, thereby making informed decisions in their deployment and optimization.\n\nFor further details, check the respective sections in the Evidently AI documentation and tutorials: \n- [LLM Jury Evaluation](https://github.com/evidentlyai/docs/tree/main/docs-main/examples/llm_jury.mdx)\n- [Evidently CI Example](https://github.com/evidentlyai/docs/tree/main/docs-main/examples/github_actions.mdx)\n- [Tracing LLM Inputs and Outputs](https://github.com/evidentlyai/docs/tree/main/docs-main/quickstart_tracing.mdx)", "id": null, "provider_details": null, "part_kind": "text"}], "usage": {"input_tokens": 1827, "cache_write_tokens": 0, "cache_read_tokens": 0, "output_tokens": 626, "input_audio_tokens": 0, "cache_audio_read_tokens": 0, "output_audio_tokens": 0, "details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}}, "model_name": "gpt-4o-mini-2024-07-18", "timestamp": "2025-12-28T08:05:19.850541Z", "kind": "response", "provider_name": "openai", "provider_url": "https://api.openai.com/v1/", "provider_details": {"finish_reason": "stop", "timestamp": "2025-12-28T08:05:08Z"}, "provider_response_id": "chatcmpl-Crg3w3L4vdFNfd4ZObg6EwViaLWWZ", "finish_reason": "stop", "run_id": "70f926e8-8bfe-40b6-a233-25d0cb4398b2", "metadata": null}], "source": "ai-generated"}